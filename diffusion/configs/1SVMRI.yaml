unets:
  unet1: # BASE
    dim: 128
    num_resnet_blocks: 2
    dim_mults: [1,2,4]
    max_text_len: 1
    layer_attns: False
    layer_cross_attns: [False, False, True]
    cond_images_channels: 1
    attend_at_middle: False

imagen:
  condition_on_text: True
  channels: 1
  elucidated: True
  image_sizes: [128]
  text_embed_dim: 1
  num_sample_steps: 64
  temporal_downsample_factor: [1]
  sigma_min: 0.002
  sigma_max: 80
  sigma_data: 0.25
  rho: 7
  P_mean: -1.2
  P_std: 1.2
  S_churn: 160 # Determined empirically as working values
  S_tmin: 0.05
  S_tmax: 50
  S_noise: 1.003

trainer:
  split_batches: False
  lr: 5e-4
  dl_tuple_output_keywords_names: ['images', 'cond_images', 'text_embeds'] #('images', 'text_embeds', 'text_masks', 'cond_images'),

dataset:
  data_path: "/home/data/datasets/ukbb_partial/twelve_slice"
  deactivate_cache: False
  time_res: 32 # IMPORTANT CHANGE IN 1SCM: 8fps instead of 32fps
  slice_res: 12
  res: 128 # resolution
  fps: 32 # frames per second
  duration: 1 #seconds
  grayscale: False

dataloader: # This is adapted when launching the training script
  batch_size: 8
  num_workers: 8

wandb:
  project: "EchoDiffusion"
  entity: "niklas-bubeck"

checkpoint:
  path: "./outputs/diffusion"
  batch_size: 4
  cond_scale: 5.
  save_every_x_it: 500